In diesem Abschnitt wird auf die Implementierung des Projekts eingegangen. Dabei wird zunächst die Projektarchitektur erklärt und dann werden die einzelnen Komponenten des Projekts, Producer, Consumer und die Webapplikation beschrieben. Zudem wird darauf eingegangen, wie die genutzten AWS Ressourcen gelöscht werden können und wie das Projekt in einem Docker Container verwendet werden kann. Zuletzt werden Abweichungen im Vergleich zur Projektplanung besprochen.
\section{Projektarchitektur}
Um die Abhängigkeitsverwaltung und das Bauen des Projektes möglichst simpel zu gestalten, wurde für das Projekt Apache Maven \cite{maven} genutzt. Apache Maven ist ein Build Manager für Java Projekte, der das Bauen von Java Applikationen sowie das Verwalten von Projektabhängigkeiten vereinfacht. Abhängigkeiten des Projekts sowie Build-Profile mit Anweisungen für den Bau des Projektes können in der ``pom.xml'' eingetragen werden und werden dann von Maven beim Bau des Projektes genutzt. \newline
Abhängigkeiten des Projekts sind der Amazon Kinesis Client in der Version 1.6.1, der Amazon Kinesis Producer in der Version 0.10.2 sowie Eclipse Jetty Servlet \cite{jetty} in der Version 9.2.14.v20151106. \newline
Teile des Codes basieren auf den Beispielen, die Amazon im AWS Kinesis Developer Guide behandelt (s. \cite{kinesis_sample_1} und \cite{kinesis_sample_2}). \newline
Die Projektarchitektur ist im Grunde genommen genau so, wie sie von Amazon in der Dokumentation von AWS Kinesis vorgestellt wird.

\begin{figure}[h!]

\includegraphics[width=1.0\textwidth]{content/images/kinesis_architecture.png}

\caption{Kinesis Architektur, wie sie von Amazon vorgegeben wird. Quelle: \cite{kinesis_concepts}}

\label{fig:aws_architecture}

\end{figure}

Wie in Abbildung \ref{fig:aws_architecture} zu sehen, setzt Amazon in der Architektur 4 Schichten voraus. Die Producer, den Kinesis Stream, die Consumer sowie weitere Services außerhalb von Kinesis. Die Daten werden von links nach rechts in der Architektur übertragen. Zunächst einmal werden die Daten in den Producern erzeugt und in den Kinesis Stream geschrieben, in denen sie in einem oder mehreren Shards einige Tage gespeichert bleiben. Ein Shard ist eine Gruppe von Datensätzen in einem Kinesis Stream, die eine feste Menge an Daten aufnehmen können. \newline
Auf der anderen Seite des Kinesis Streams befinden sich ein oder mehrere Consumer, die die Daten aus den Shards des Kinesis Streams lesen. Nach dem Lesen können die Daten zudem an andere Services weitergeleitet werden, wie beispielsweise Amazon DynamoDB, mit dem die Daten in der NoSQL-Datenbank von DynamoDB persistiert werden können. \newline
Genau diese Architektur wurde auch im Projekt umgesetzt. Es gibt eine oder mehrere Instanzen des Producers, der Temperaturdaten erzeugt. Der Producer schreibt die Daten in einen Kinesis Stream, meist nur mit einem Shard, da ein Shard für die Datenmengen dieses Projekts ausreicht. Zudem gibt es eine oder mehrere Instanzen eines Consumers, der die Daten aus dem Kinesis Stream liest und dann in eine DynamoDB Datenbank schreibt. Darüber hinaus enthält dieses Projekt zudem eine Webapplikation, die die Temperaturdaten aus DynamoDB liest und in Diagrammen ausgibt. \newline
Zudem enthält das Projekt Utility-Klassen für DynamoDB, Kinesis sowie zur Temperaturgenerierung, in denen Methoden für die entsprechenden Anforderungsgebiete ausgelagert wurden. Darüber hinaus enthält das Projekt eine \texttt{DeleteResources} Klasse, die eine Methode zur Löschung aller verwendeten Ressourcen auf Amazon Webservices bereitstellt. \newline
In der pom.xml des Projekts sind mehrere Profile eingetragen, die es ermöglichen, einzelne Klassen mit Startparametern auszuführen um somit beispielsweise den Producer mit anderen Parametern zu starten (siehe Kapitel \ref{producer}). 

\section{Producer}
\label{producer}

Der Producer ist für die Erzeugung  und Übermittlung der Temperaturwerte zuständig. Er erzeugt zunächst die Temperaturwerte und verschickt diese dann an AWS Kinesis zur weiteren Verarbeitung. Er ist also das Äquivalent zu einem Sensor, der in diesem Fall die Temperaturen aber generiert und nicht aus der Umwelt misst. Es können mehrere Instanzen des Producers erzeugt und gestartet werden um auf diese Weise mehrere Sensoren zu simulieren. Der Producer besteht aus einer einzelne Java-Klasse, die auf mehrere weitere Utility-Klassen zugreift. Darunter fällt die \texttt{Utils}-Klasse, die die Temperaturdaten erzeugt sowie die \texttt{StreamUtils}-Klasse, die Methoden zum Zugriff auf AWS Kinesis Streams bereitstellt. Der Producer enthält eine Main-Methode, über die er gestartet werden kann. Zunächst werden die übergebenen Parameter ausgelesen und gesetzt. Die Parameter sind der Name des Streams, der Sensorname, die Dauer der Ausführung sowie die Anzahl der Temperaturwerte pro Sekunde. Des Weiteren wird ein AWS Access Key sowie ein AWS Secret Key übergeben. Diese Keys werden zur Identifikation gegenüber den AWS Servern benötigt und gehören zu genau einem Account, mit dem die Services dann genutzt werden. Diese Schlüssel sind nicht statisch im Code vorhanden, da sie sonst ausgelesen werden könnten und von nicht berechtigten Personen zum Zugriff auf den AWS Account genutzt werden könnten und somit jeder Nutzer seinen eigenen Account nutzen kann. \newline
Zudem wird ein Objekt der \texttt{StreamUtils} Klasse initialisiert, damit die Methoden der Klasse benutzt werden können. Schon bei der Initialisierung der Klasse wird der erste Temperaturwert generiert, der nun als Basis für alle weiteren Temperaturwerte dieser Iteration fungiert. Es werden außerdem weitere Variablen initialisiert, zum Beispiel ein \texttt{ScheduledExecutorService}, mit dem die Temperaturen in bestimmten Intervallen abgesendet werden können.  \newline \newline
\lstinputlisting[firstline=54, lastline=56, caption=Utils.java (ll. 54-56): Initialisierung des Temperaturwertes, label=utils_init, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_init} zeigt die Methode \texttt{getFirstTemperature}, die einen Zufallswert zwischen zwei Schranken ausgibt, der dann als erster Temperaturwert genutzt wird. Diese Schranken sind in diesem Fall -20 und 40, können aber auch im Code angepasst werden. Dementsprechend kann der initiale Temperaturwert nur innerhalb dieser Schranken liegen. Der Rückgabewert dieser Methode wird der Temperaturvariable zugewiesen.
\lstinputlisting[firstline=105, lastline=123, caption=StreamUtils.java (ll. 105-123): Erstellung eines neuen Kinesis Streams, label=create_stream, style=java]{content/listings/StreamUtils.java}
Als nächstes wird ein Kinesis-Stream erzeugt, falls nicht schon ein Stream vorhanden ist. Dazu wird mit der Methode \texttt{describeStream} der Kinesis Client Library ein \texttt{DescribeStreamResult} Objekt des Streams ermittelt (s. Quelltext \ref{create_stream}) und geprüft, ob der Stream schon erstellt wurde und aktiv ist. Wenn dies nicht der Fall ist, wird ein neuer Stream erzeugt und darauf gewartet, dass dieser aktiv wird.
\lstinputlisting[firstline=229, lastline=250, caption=TemperatureProducer.java (ll. 229-250): Initialisierung eines \texttt{Callbacks} um Rückmeldungen der Threads zu bekommen, label=temperatureProducer_callback, style=java]{content/listings/TemperatureProducer.java}
Wie in Quelltext \ref{temperatureProducer_callback} zu sehen, wird ein \texttt{FutureCallback} initialisiert, der die Möglichkeit bietet nach jeder Iteration eines Threads auf das Ergebnis dieser Iteration zu reagieren. Bei einem Fehler wird hier also eine Fehlermeldung ausgegeben, bei Erfolg wird ein neuer Temperaturwert erzeugt. 
\lstinputlisting[firstline=44, lastline=52, caption=Utils.java (ll. 44-52): Generierung des nächsten Temperaturwertes, label=utils_next, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_next} zeigt die Erzeugung eines neuen Temperaturwertes. Dazu wird mit einer jeweils etwa 33 prozentigen Wahrscheinlichkeit der Temperaturwert um 0,1 erhöht bzw. erniedrigt oder bleibt wie er vorher war. Der Rückgabewert wird zudem auf eine Dezimalstelle gerundet.

\lstinputlisting[firstline=253, lastline=264, caption=TemperatureProducer.java (ll. 253-264): Initialisierung eines Runnables zum Senden eines Records, label=temperatureProducer_runnable, style=java]{content/listings/TemperatureProducer.java}

Quelltext \ref{temperatureProducer_runnable} zeigt die Initialisierung eines Runnables, der die Temperaturdaten an Kinesis schickt. Hier werden zunächst die Temperaturdaten erzeugt, die mithilfe des Kinesis Producers aus der Amazon Kinesis Java API verschickt werden. Das Ergebnis des Sendeversuchs wird an den \texttt{Callback} zurückgegeben. Die Erzeugung der Daten erfolgt in der Methode \texttt{Utils.generateData}

\lstinputlisting[firstline=73, lastline=91, caption=Utils.java (ll. 73-91): Generierung der zu verschickenden Daten, label=utils_generate_data, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_generate_data} enthält die Methode \texttt{Utils.generateData}. Hier wird mit einem \texttt{Stringbuilder} ein String erzeugt, der dann als \texttt{Bytebuffer} der aufrufenden Methode zurückgegeben wird. Der erzeugte String besteht aus der Temperatur, dem Sensornamen und der aktuellen Zeit in Millisekunden, alle getrennt durch ein Semikolon. Es wird zudem nicht einfach nur die übergebene Temperatur genommen, sondern noch einmal die nächste Temperatur generiert, obwohl dieses auch im \texttt{Callback} wie oben genannt passiert. Dies erhöht die Zufälligkeit der Temperaturänderungen.

\lstinputlisting[firstline=267, lastline=279, caption=TemperatureProducer.java (ll. 267-279): Status Updates jede Sekunde über ein\texttt{ Runnable} im \texttt{Executor}, label=temperatureProducer_status, style=java]{content/listings/TemperatureProducer.java}
Im Producer wird nun dem \texttt{ScheduledExecutorService} (Variable `\texttt{EXECUTOR}) ein weiteres \texttt{Runnable} hinzugefügt, das einmal pro Sekunde ausgeführt wird. Dieser übergebene Task startet sofort und gibt einmal pro Sekunde den aktuellen Status der Übertragung aus (s. Quelltext \ref{temperatureProducer_status})
\lstinputlisting[firstline=285, lastline=286, caption=TemperatureProducer.java (ll. 285-286): Start der Puts zu Kinesis, label=temperatureProducer_start, style=java]{content/listings/TemperatureProducer.java}

Nach der Initialisierung aller Variablen wird nun das Verschicken der Temperaturdaten gestartet. Dies geschieht über den Aufruf in Quelltext \ref{temperatureProducer_start}. \newline
Die Methode \texttt{executeAtTargetRate} bekommt als Parameter den \texttt{ScheduledExecutorService}, der das \texttt{Runnable} zur Statusausgabe beinhaltet, sowie das \texttt{Runnable} zum Verschicken eines Records und zudem, welche Sequenznummer aktuell verschickt wird und wie lange Daten verschickt werden sollen und wie viele pro Sekunde. \newline

\lstinputlisting[firstline=327, lastline=355, caption=TemperatureProducer.java (ll. 327-355): Die Methode \texttt{exectueAtTargetRate}, label=temperatureProducer_execute, style=java]{content/listings/TemperatureProducer.java}
Quelltext \ref{temperatureProducer_execute} zeigt die Methode \texttt{executeAtTargetRate}. Hier wird dem \texttt{ScheduledExecutorService} ein weiteres \texttt{Runnable} übergeben, das das Verschicken der Daten an Kinesis koordiniert. Je nachdem welche Parameter dem Producer übergeben wurden, wird der übergebene Task nun entsprechend lange und häufig ausgeführt. Der Task selbst ist das \texttt{Runnable}, das vor der Methode initialisiert wurde und die Temperaturdaten an Kinesis schickt (\texttt{Runnable putOneRecord}). \newline
Wenn alle Puts abgeschlossen sind, terminiert die Methode. Daraufhin wird noch darauf gewartet, dass alle abgeschlossenen Puts auch wirklich von Kinesis verarbeitet wurden. Dann wird der Producer terminiert. \newline
Wie man sieht, werden alle Funktionen des Producers asynchron in seperaten Threads ausgeführt. Diese werden zunächst als Runnables deklariert und im \texttt{ScheduledExecutorService} registriert, so dass sie in einem bestimmten Intervall ausgeführt werden. Die Methode \texttt{executeAtTargetRate} sorgt zudem dafür, dass nur im gewählten Intervall Daten an Kinesis verschickt werden.
\section{Consumer}
Der Consumer liest die vom Producer übermittelten Daten aus AWS Kinesis und persistiert diese in AWS DynamoDB zur weiteren Verarbeitung. Er ist eine einzelne Java-Klasse, die auf mehrere weitere Utility-Klassen zugreift. Darunter fällt die \texttt{StreamUtils}-Klasse, die Methoden zum Zugriff auf AWS Kinesis Streams bereitstellt sowie die \texttt{DynamoDBUtils}-Klasse, die Methoden zum Zugriff auf AWS DynamoDB bereitstellt. Der Consumer enthält eine Main-Methode, über die der er gestartet werden kann. Als Parameter wird dem Consumer der Name des Streams sowie der Name der DynamoDB Tabelle übergeben. Die Access und Secret Keys werden ebenfalls wieder übergeben. Außerdem werden jeweils eine Instanz der \texttt{Streamutils} Klasse sowie der \texttt{DynamoDBUtils}-Klasse initialisiert, damit die Methoden der Klassen genutzt werden können. \newline
Zunächst wird die DynamoDB Tabelle gelöscht, die Informationen eines \texttt{Checkpointers} sichert, da die dort gesicherten Daten nicht mehr aktuell sind. Der \texttt{Checkpointer} wird nach dem Lesen einer bestimmten Menge an Temperaturen aufgerufen und speichert Informationen über die gelesen Daten in der DynamoDB Tabelle ab, zum Beispiel die Sequenznummer des letzten gelesenen Wertes. Außerdem wird die Tabelle, in der die Temperaturdaten gespeichert werden, auf Amazon DynamoDB mittels der Methode \texttt{createTemperatureTableIfNotExists} der \texttt{DynamoDBUtils} erzeugt, falls sie nicht schon existierte.
\lstinputlisting[firstline=95, lastline=99, caption=DynamoDBUtils.java (ll. 95-99): Setzung des Hashkeys und Rangekeys der Temperaturtabelle, label=DynamoDBUtils_keys, style=java]{content/listings/DynamoDBUtils.java}
Quelltext \ref{DynamoDBUtils_keys} zeigt einen Ausschnitt der Methode \texttt{createTemperatureTableIfNotExists}, in der die Hash- und Rangekeys der Tabelle gesetzt werden. Bei der Temperaturtabelle wird als Hashkey der Sensorname gesetzt und als Rangekey der Zeitstempel des Sensordurchlaufs. Der Hashkey partitioniert die Daten in mehrere Blöcke, in diesem Fall in Datenblöcke der einzelnen Sensoren. Mittels des Rangekeys können die partitionierten Daten zudem sortiert werden. Zusammengenommen ergeben der Hashkey und der Rangekey den Primary Key der Daten.
\lstinputlisting[firstline=241, lastline=244, caption=TemperatureConsumer.java (ll. 241-244): Erzeugung und Starten des \texttt{IRecordProcessors}, label=TemperatureConsumer_recordprocessor, style=java]{content/listings/TemperatureConsumer.java}
Nach dem Erzeugen der Temperaturtabelle wird eine Instanz des \texttt{TemperatureConsumers} erzeugt und über eine \texttt{IRecordProcessorFactory} ein \texttt{IRecordProcessor} erzeugt und gestartet (s. Quelltext \ref{TemperatureConsumer_recordprocessor}). Der Consumer implementiert das \texttt{IRecordProcessorFactory} Interface und fungiert als Fabrik für den \texttt{IRecordProcessor}. In einer inneren Klasse ist zudem das \texttt{IRecordProcessor} Interface implementiert. Mittels des \texttt{IRecordProcessor} kann über die Records innerhalb eines Kinesis Streams iteriert werden und die Daten können weiterverarbeitet werden, also bspw. in einer Datenbank persistiert werden. \newline
Der Consumer entählt eine innere Klasse namens \texttt{RecordProcessor}, in der drei Methoden des \texttt{IRecordProcessor} Interfaces implementiert wurden. In der \texttt{initialize} Methode wird eine Instanz der \texttt{DynamoDBUtils} erzeugt. In der \texttt{shutdown} Methode wird der Grund des Abbruchs ins Log geschrieben und außerdem ein Eintrag in der Checkpointer Tabelle erzeugt. Die dritte implementierte Methode ist die \texttt{processRecords} Methode, die die Records verarbeitet.
\lstinputlisting[firstline=121, lastline=123, caption=TemperatureConsumer.java (ll. 121-123): Initialisierung von Variablen in der \texttt{processRecords} Methode, label=TemperatureConsumer_processrecords_init, style=java]{content/listings/TemperatureConsumer.java}
Zunächst werden wie in Quelltext \ref{TemperatureConsumer_processrecords_init} zu sehen einige Variablen initialisiert. Es wird die Variable \texttt{timestamp} initialisiert, die den Zeitstempel des aktuellen Temperaturwertes annimmt. Die Variable \texttt{count} entspricht der Anzahl der Temperaturwerte. Die HashMap \texttt{allTemperatures} nimmt die Werte aller Temperaturen auf. Der Key der Hashmap ist der Sensorname und damit der Hashkey der DynamoDB Tabelle. Die Werte sind weitere HashMaps. Keys dieser Hashmaps sind die timeStamps der Temperaturen. Die Werte sind die Temperaturdaten. Die Temperaturdaten werden also in mehreren Schichten von Hashmaps gespeichert. Der Zeitstempel des Durchlaufs liest der \texttt{IRecordProcessor} als PartitionKey aus dem Stream und bildet den Rangekey.
\lstinputlisting[firstline=124, lastline=149, caption=TemperatureConsumer.java (ll. 124-149): Iteration über die Records innerhalb eines Streams, label=TemperatureConsumer_processrecords_process, style=java]{content/listings/TemperatureConsumer.java}
Der Quelltext \ref{TemperatureConsumer_processrecords_process} zeigt den Verarbeitungsprozess der Daten in der Methode \texttt{processRecords}. Es wird über alle Records iteriert und zunächst der Zeitstempel als Rangekey extrahiert. Dann werden die Daten des Records extrahiert. Der im Producer erzeugte String wird dabei in die einzelnen Teile aufgeteilt und enthält die Daten für einen Temperaturwert eines Sensors, gemessen an einem bestimmten Zeitpunkt.. Als nächstes wird geprüft, ob in der Hashmap \texttt{allTemperatures} schon eine Hashmap für den Sensor, der den Temperaturwert erzeugt hat, vorhanden ist. Wenn ja, wird diese Hashmap aus \texttt{allTemperatures} gelesen, ansonsten wird eine neue erzeugt. In diese Hashmap wird nun der Temperaturwert und der Zeitpunkt eingefügt und die aktualisierte Map des Sensors wird wieder in die \texttt{allTemperatures} Hashmap eingefügt. Es wird ein Log mit den gelesenen Daten ausgegeben und der Zähler der Temperaturen inkrementiert.
\lstinputlisting[firstline=157, lastline=165, caption=TemperatureConsumer.java (ll. 157-165): Persistieren der Temperaturen auf DynamoDB, label=TemperatureConsumer_processrecords_persist, style=java]{content/listings/TemperatureConsumer.java}
Nach dem Lesen aller Daten dieses Durchlaufs werden die gesammelten Temperaturdaten in der DynamoDB Tabelle, wie in Quelltext \ref{TemperatureConsumer_processrecords_persist} zu sehen, persistiert. Außerdem wird der \texttt{Checkpointer} aufgerufen und ein Eintrag in der Checkpointer Tabelle erzeugt.
\lstinputlisting[firstline=158, lastline=184, caption=DynamoDBUtils.java (ll. 158-184): Persistierung der Daten auf DynamoDB, label=DynamoDBUtils_put, style=java]{content/listings/DynamoDBUtils.java}
Der Quelltext \ref{DynamoDBUtils_put} zeigt die Methode \texttt{putTemperatures} in der Klasse \texttt{DynamoDBUtils}, die im Consumer aufgerufen wird. Hier wird jeder einzelne Sensor einzeln in einer For-Schleife abgearbeitet. Für jeden Sensor wird eine Query auf der Tabelle ausgeführt, die die Temperaturdaten eines Sensordurchlaufs für den gegebenen Sensornamen und den Zeitstempel zurückgibt. Das Ergebnis ist eine Liste von Maps, die entweder genau eine Map enthält oder keine, falls es noch keine Temperaturdaten für diesen Sensordurchlauf gibt. Dann wird eine neue Map erzeugt. Alle der Methode übergebenen Temperaturen werden in diese neue Map eingefügt. Daraufhin wird die Map wieder in die DynamoDB Tabelle eingefügt und diese Tabelle persistiert. Damit sind die Temperaturen auf DynamoDB aktualisiert. \newline
Die Methode \texttt{processRecords} wird vom \texttt{IRecordProcessor} je nach Datenmenge mehrfach mit einem Teil der Daten, der aus dem Stream gelesen wurde, als Parameter aufgerufen. Wenn alle Daten gelesen wurden, bleibt der Consumer zunächst in einem Wartezustand, bis weitere Daten gelesen werden können.
\section{Webapplikation}
Die Webapplikation besteht aus einem Servlet sowie der Klasse \texttt{Servletstarter}, die einen Jetty \cite{jetty} Server startet und das Servlet einbindet. Auf der vom Servlet generierten Website können dann die aktuellen Temperaturwerte eingesehen werden, die aus der DynamoDB-Tabelle ausgelesen werden.

\lstinputlisting[firstline=34, lastline=39, caption=ServletStarter.java (ll. 34-39): Auslesen der übergebenen Argumente in \texttt{ServletStarter}, label=servletStarter_init_variables, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_init_variables} werden die übergebenen Parameter ausgelesen und initialisiert. Zudem wird eine \texttt{Server} Instanz erzeugt, die auf dem Port 8080 betrieben wird.

\lstinputlisting[firstline=41, lastline=46, caption=ServletStarter.java (ll. 41-46): Servlet wird in \texttt{ServletContextHandler} eingebunden, label=servletStarter_context, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_context} wird der \texttt{ServletContextHandler} initialisiert und das Servlet wird in den \texttt{ServletContextHandler} mittels eines \texttt{ServletHolders} eingebunden. Das Servlet ist damit also nach Start des Servers unter der Adresse ``localhost:8080/api/GetTemperature'' erreichbar.

\lstinputlisting[firstline=48, lastline=54, caption=ServletStarter.java (ll. 48-54): \texttt{ServletContextHandler} wird der Handlerliste zugefügt, label=servletStarter_handler, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_handler} wird der \texttt{ServletContextHandler} dann der Handlerliste zugefügt, die Handlerliste dem \texttt{server} zugeordnet und der \texttt{server} dann gestartet. \newline
Das Servlet selbst besteht aus einer \texttt{doGet}-Methode, die bei einem GET auf die oben genannte URL aufgerufen wird. 
\lstinputlisting[firstline=64, lastline=67, caption=TemperatureServlet.java (ll. 64-67): Aufruf der Methode zum Lesen aller Temperaturen von DynamoDB, label=temperatureServlet_getTemperatures, style=java]{content/listings/TemperatureServlet.java}
Quelltext \ref{temperatureServlet_getTemperatures} zeigt die Initialisierung einer Hashmap, die alle Temperaturdaten enthalten wird, sowie den Aufruf der Methode \texttt{getAllSensorTemperatures}, die die HashMap befüllt.
\lstinputlisting[firstline=228, lastline=242, caption=DynamoDBUtils.java (ll. 228-242): Die Erzeugung einer HashMap mit allen Temperaturen, label=DynamoDBUtils_getAllTemps, style=java]{content/listings/DynamoDBUtils.java}
Quelltext \ref{DynamoDBUtils_getAllTemps} zeigt die Methode \texttt{getAllSensorTemperatures}, die die oben genannte HashMap erzeugt. In der Methode werden zunächst mittels eines \texttt{Scanrequests} die Namen aller in der DynamoDB Tabelle vorhandenen Sensoren ermittelt. Dann wird für jeden Sensor eine eigene Hashmap erzeugt, die die Temperaturdaten enthält. 
\lstinputlisting[firstline=198, lastline=217, caption=DynamoDBUtils.java (ll. 198-217): Die Erzeugung einer HashMap mit allen Temperaturen eines Sensors, label=DynamoDBUtils_getOneTemp, style=java]{content/listings/DynamoDBUtils.java}
Die Hashmaps der einzelnen Sensoren werden in der Methode \texttt{getTemperaturesForSensor} erzeugt, die in Quelltext \ref{DynamoDBUtils_getOneTemp} zu sehen ist. Hier wird zunächst eine Query mit dem Hashkey als Parameter abgesetzt, die alle Temperaturen für einen Sensor zurückliefert. Daraufhin wird über die Items der Query iteriert und die HashMap der Temperaturdaten dieses Sensors erzeugt. In der Methode \texttt{getAllSensorTemperatures} werden alle Hashmaps der Sensoren in einer übergeordneten Hashmap zusammengefügt. \newline
Die daraus generierte Hashmap zeigt auf eine weitere Menge von Hashmaps, die wiederum auf eine Menge von HashMaps zeigt. Die Temperaturdaten sind also schichtenweise aufgeteilt. Die erste Schicht ist die erste Hashmap, deren Keys die Sensornamen sind. Die Sensornamen zeigen jeweils auf eine weitere HashMap. Als Schlüssel dient der Zeitstempel des Sensordurchlaufs. Wurde ein Sensor also mehrmals gestartet, hat dieser mehrere Einträge in dieser HashMap. Die Werte dieser HashMap sind jeweils eine weitere HashMap. Diese enthält als Keys den Zeitstempel, an dem die Temperatur gemessen wurde und als Werte den entsprechenden Temperaturwert. Durchläuft man diese Hierarchie von oben nach unten, werden also den Sensoren eine Menge von Zeitstempeln der Iterationen zugeordnet. Den Zeitstempel der Iterationen wird nun eine Menge von Temperaturen zugeordnet, die zudem jeder einen Zeitstempel enthalten, um sie in eine zeitliche Reihenfolge einzuordnen.  \newline
In der Methode wird nun über die einzelnen Schichten dieser HashMap iteriert und dabei mittels einem \texttt{PrintWriter} das erzeugte HTML ausgegeben. Hierbei werden HTML und Javascript Daten generiert, die dann von CanvasJS \cite{canvasjs} als Input genutzt, um die Temperaturdaten als Graphen darzustellen.

\lstinputlisting[firstline=75, lastline=89, caption=TemperatureServlet.java (ll. 75-89): Iteration über die HashMaps, label=temperatureServlet_iteration, style=java]{content/listings/TemperatureServlet.java}
Quelltext \ref{temperatureServlet_iteration} zeigt die Iteration über die HashMaps. CanvasJS nimmt ein Array an, das die Datenpunkte als y und y Werte enthält. Hier wird für jeden Sensordurchlauf ein eigenes Javascript-Array erzeugt, da jeder Sensordurchlauf in einem eigenen Graphen dargestellt werden soll. In der innersten For-Schleife werden dem Array dann die Datenpunkte hinzugefügt. Als x Koordinate wird eine laufende Nummer vergeben, da die Zetstempel der Temperaturen zu groß für die Anzeige wären und als y Koordinate wird die Temperatur gesetzt. \newline
Wenn alle Datapoint-Arrays erzeugt wurden, werden weitere Metadaten für die Generierung der Graphen ausgegeben. Es wird zudem für jeden Graphen ein div Element im body Tag des HTML Dokuments erzeugt, in das der Graph dann generiert wird. Bei Aufrufen der Webseite wird dann eine Javascript Funktion aufgerufen, die die Graphen in den divs rendert. \newline
Die Webseite stellt nun alle Durchläufe der Sensoren dar. Für jeden Durchlauf gibt es einen Graphen, der wie oben beschrieben initialisiert wurde. CanvasJS bietet nun die Möglichkeit die Graphen zu manipulieren indem bspw. der betrachtete Zeitraum verändert wird und nur ein Teil der Daten dargestellt wird.
\section{Löschung der AWS Ressourcen}

Eine weitere Klasse ist die Klasse \texttt{DeleteResources}, mittels der man die gestarteten Ressourcen auf Amazon Webservices wieder löschen kann, um keine weiteren Kosten zu verursachen. Dazu zählen zum einen der Kinesis Stream sowie die beiden DynamoDB Datenbanken, die die Temperaturdaten aufnehmen. Werden diese nicht gelöscht, verursachen sie dauerhaft eine kleine Menge an Kosten für die Datenhaltung. In einem echten Projekt würden die Ressourcen nicht gelöscht werden, da gesammelte Daten nicht verloren gehen sollten, aber in diesem Projekt sind die Daten nicht wichtig und so können durch die Ersparnis der Datenhaltungskosten mehr vom Budgets für andere Kapazitäten genutzt werden.  \newline
Die Klasse hat eine main-Methode, die zwei Argumente annimmt: Den Name des Streams sowie den Namen der Dynamo DB Tabelle.
\lstinputlisting[firstline=24, lastline=30, caption=DeleteResources.java (ll. 24-30): Auslesen der übergebenen Argumente in \texttt{DeleteResources}, label=deleteresources_init_variables, style=java]{content/listings/DeleteResources.java}
In Quelltext \ref{deleteresources_init_variables} sieht man, wie die Argumente ausgelesen und gesetzt werden. Wenn nicht genau 2 Argumente übergeben werden, wird ein Standardwert für die beiden Variablen genutzt. 
\lstinputlisting[firstline=32, lastline=43, caption=DeleteResources.java (ll. 32-43): Initialisierung der \texttt{DynamoDBUtils}-Klasse und Löschen der Tabellen, label=deleteresources_init_db, style=java]{content/listings/DeleteResources.java}
In Quelltext \ref{deleteresources_init_db} wird die \texttt{DynamoDBUtils}-Klasse initalisiert und dazu werden zunächst die benötigten Amazon Client Klassen erzeugt, die der \texttt{Util}-Klasse bei der Initialisierung übergeben werden. Daraufhin wird die Übersichtstabelle sowie die Tabelle, die die Temperaturdaten enthält, gelöscht.
\lstinputlisting[firstline=45, lastline=49, caption=DeleteResources.java: Initialisierung der \texttt{StreamUtils}-Klasse und Löschen des Streams (ll. 45-49), label=deleteresources_init_stream, style=java]{content/listings/DeleteResources.java}
Im nächsten Abschnitt in Quelltext \ref{deleteresources_init_stream} wird dann die \texttt{StreamUtils}-Klasse initialisiert und daraufhin der Stream gelöscht. \newline
Damit sind alle Ressourcen, die auf Amazon Web Services genutzt wurden, gelöscht und es werden keine Kosten mehr, zum Beispiel durch die temporäre Speicherung der Daten im Kinesis Stream, verursacht.
\section{Docker}

Um die Applikation auf ein Deployment auf Amazon EC2 vorzubereiten, wurde ein Docker Image erstellt, um die Applikation letztendlich über ECS auf EC2 zu deployen. Das Image wird in einem Dockerfile beschrieben, das zum einen die Basisimages beschreibt, auf dem dieses Image aufbaut, als auch Befehle, die bei Erzeugung des Images und Start des Containers ausegeführt werden sollen.
\lstinputlisting[firstline=1, lastline=2, caption=Dockerfile des Projekts, label=dockerfile, style=java]{content/listings/Dockerfile.txt}
Dieses Dockerfile ist sehr simpel gehalten und enthält nur 2 Zeilen. Wie in Quelltext \ref{dockerfile} zu sehen, basiert dieses Image auf dem Apache Maven Image \cite{maven_image}. Dieses Image enthält neben einer Java 7 Installation auch eine Maven 3.2 Installation. Zudem kopiert es bei der Generierung des Images das Projekt, wenn das Dockerfile im gleichen Ordner wie die pom.xml ist, nach ``/usr/src/app'' und führt ``mvn install'' aus. Zusätzlich dazu wird, wie in Zeile 2 beschrieben, noch ``mvn clean package'' ausgeführt, was die Applikation endgültig initialisiert. \newline
Mithilfe dieses Dockerfiles kann nun mit \texttt{docker build -t project-image .} ein Docker Image erzeugt werden. Über dieses Image kann dann mit dem Befehl in Quelltext \ref{start_docker} der Producer gestartet werden. 
\lstinputlisting[firstline=1, lastline=1, caption=Konsolenbefehl zum Starten des Docker Images, label=start_docker, style=java]{content/listings/Start_Docker.txt}
Auch hier müssen wieder der AWS Access Key sowie der AWS Secret Key (s. Kapitel \ref{producer}) übergeben werden sowie die weiteren Parameter, die der Producer annimmt. In diesem Beispiel wird ein Stream namens ``StreamTest'' erzeugt, der Sensor Name ist ``SensorTest'' und der Producer erzeugt für 10 Sekunden 10 Records pro Sekunde. Es ist natürlich auch möglich die anderen Klassen mithilfe dieses Images zu starten, indem die Übergabeparameter geändert werden.\newline
Wird der Container nicht lokal ausgeführt, sondern mittels ECS auf Amazon EC2 ausgeführt, muss eine IAM Role \cite{iam} für diese Applikation erstellt werden. IAM Roles bestimmen die Rechte, die ein User oder ein Service auf Amazon Web Services besitzt. So können bspw. die Rechte eines Users oder eines Accounts, der von mehreren Personen genutzt wird (bspw. Account eines Unternehmens) beschränkt werden. Genauso können aber auch Services wie bspw. eine Applikation, die auf Amazon EC2 ausgeführt wird, bestimmte Rechte bekommen oder entzogen werden. In diesem Fall muss die IAM Role der Applikation den Zugriff auf Amazon Kinesis sowie Amazon DynamoDB ermöglichen, da diese von der Applikation genutzt werden. Dies ersetzt die AWS Access und Secret Keys, die lokale Anwendungen für den Zugriff auf Amazon Webservices benötigen. \newline
 Um den Container auf ECS zu deployen muss nun ein Cluster erstellt werden. Ein ECS Cluster vereint zusammenhängende Services und diese führen bspw. Docker Container aus. In dem erstellten Cluster muss nun ein Service erzeugt werden und diesem das oben genannte Docker Image übergeben werden. Dies wird über Docker Hub \cite{dockerhub} zur Verfügung gestellt. Docker Hub ist ein Online-Dienst, der Docker Images bereitstellt und auf der auch Nutzer eigene Docker Images zur Verfügung stellen können. Auf dieser Plattform muss das Image in ein Repository eingebunden werden und kann dann von ECS aus diesem Repository geladen werden. Im ECS Service müssen nun noch einige Einstellungen vorgenommen werden wie z.B. die Größe des EC2 Containers, Ports die freigegeben werden müssen wie bspw. Port 80 bei einer Webapplikation oder benötigter Festplattenspeicher, falls die Applikation diesen benötigt. Zudem werden die Parameter angegeben, die auch lokal dem Container übergeben werden (s. Quellcode \ref{start_docker}) und dann kann der Service gestartet werden. Der Container wird von ECS auf einer EC2 Instanz der gewählten Größe deployed und die EC2 Instanz wird gestartet. Beim Start wird auch der Container mit den angegebenen Parametern gestartet und nun auf der EC2 Instanz ausgeführt.
\section{Abweichungen im Vergleich zur Projektplanung}
\label{abweichungen}
In der Projektplanung wurden die Anforderungen des Projekts ermittelt und darauf basierend ein Pflichtenheft erstellt, das die Anforderungen an das Projekt präzise darstellt. Einige dieser Anforderungen konnten aber im Laufe dieses Projektes nicht erfüllt werden. Zum einen konnte die Anforderung  ``Mehrere AWS Services'' nicht erfüllt werden. Während der Entwicklung wurde klar, dass AWS Kinesis eine sehr effiziente und schnelle Lösung für die Übertragung der Daten ist und es zumindest von Amazon keine passende Alternative gibt, die für dieses Projekt genutzt werden konnte. Es wäre möglich gewesen, Amazon Kinesis Firehose  \cite{firehose} zu nutzen, das eine Variante von Kinesis darstellt, um Daten über Kinesis direkt an andere Datenbankservices wie Amazon S3 \cite{s3} weiterzuleiten, wo sie dann persistiert werden. Allerdings bietet Amazon Kinesis Firehose keine Integration für Amazon DynamoDB, das in diesem Projekt das gewählte Datenbanksystem darstellt. Eine Umstellung hätte zu viel Zeit gekostet. Genauso war für eine Eigenentwicklung, die beispielsweise auf Amazon EC2 hätte deployed werden können, am Ende des Projektes keine Zeit mehr. Daher blieb es bei der einen implementierten Variante. \newline
Die Anforderung ``Dashboard Start Stopp'' wurde auch nicht komplett umgesetzt. Die Producer lassen sich zwar stoppen und wieder starten, allerdings nicht über das Dashboard, sondern indem der EC2 Container gestoppt wird, in dem der Producer betrieben wird.  ``Dashboard Zeitskalierung'' wurde auch nicht ganz umgesetzt, es ist nur möglich beim Start eines Producers die Menge der zu erzeugenden Daten zu bestimmen und nicht, wenn ein Producer schon gestartet ist. \newline
Des Weiteren wurden die Anforderungen ``Dashboard Diagramme Aktualität'' sowie ``Producer Temperatur Beeinflussung'' nicht vollständig umgesetzt. Die Diagramme sind beim Aufruf des Dashboards aktuell, werden aber nicht aktualisiert, wenn die Seite durch den Benutzer nicht aktualisiert wird. Zudem beeinflussen sich die Producer nicht gegenseitig. \newline
Dementsprechend wurden die ursprünglichen Anforderungen ``Start und Stopp des Datenstroms'', ``Mehrere AWS Services'', ``Aktualität der Daten'' sowie ``Temperaturen beeinflussen sich gegenseitig'' nicht oder nur teilweise erfüllt. \newline
In der Projektanalyse wurde zudem eine Risikoanalyse durchgeführt, die die Risiken des Projektes auflistet. Im Projekt sind die Risiken Nummer drei und vier zumindest teilweise auch eingetreten. Der Umfang des Projektes wurde etwas unterschätzt und dadurch wurden Teile des Projekts nicht fertig. Allerdings wurden im Rahmen der Risikoanalyse auch Gegenmaßnahmen entwickelt, um die Kosten der Risiken abzufedern. So wurde die Wichtigkeit der Anforderungen ermittelt und dementsprechend priorisiert, so dass die wichtigsten Anforderungen möglichst früh abgearbeitet wurden. Dabei wurde auch erkannt, dass einige Anforderungen für den Erfolg des Projektes nicht entscheidend sind und das Projekt nur abgerundet hätten. Daher konnte das Projekt trotz dem Eintritt zweier Risiken erfolgreich durchgeführt werden.  \newline
Das Budget von 200\texteuro{} wurde innerhalb des Projektes nicht ausgereizt, da auch entsprechend der Risikoplanung die Kosten ständig überwacht wurden. \newline
Zusammenfassend kann man also sagen, dass es einige Abweichungen im Vergleich zur Projektplanung gab, aber trotzdem alle wichtigen Anforderungen umgesetzt wurden und die Maßnahmen im Rahmen der Risikoplanung gegriffen haben.
\section{Zusammenfassung}
Insgesamt kann man sagen, dass das Projekt zufriedenstellend abgelaufen ist. Es sind zwar einige Anforderungen nicht erfüllt worden, allerdings wurden alle für das Projekt wichtigen Anforderungen erfüllt und die genutzten Amazon Webservices können evaluiert werden. Die nicht umgesetzten Anforderungen können unter Umständen in einem weiteren Projekt nach dieser Bachelorarbeit erarbeitet werden, um noch weitere Kenntnisse über Amazon Web Services zu gewinnen und das Projekt in einigen Punkten noch zu verbessern.  \newline
Positiv ist die Planungsphase und insbesondere die Risikoplanung zu sehen, dank der die wichtigsten Anforderungen erfüllt werden konnten und auch das Budget eingehalten werden konnte. \newline
Schade ist, dass die Amazon Kinesis Connectors \cite{kinesisconnector} nicht genutzt werden konnten, da die Dokumentation dieser leider etwas kurz ist und zu viel Einarbeitungszeit benötigt hätte. Mittels Kinesis Connectors hätte man die Persistierung der Temperaturdaten auf DynamoDB automatisieren können, so dass gar kein Consumer mehr nötig gewesen wäre, sondern die Daten direkt von Kinesis an DynamoDB weitergeleitet werden. \newline
Zusammenfassend ist das Projekt also zufriedenstellend erfüllt worden.