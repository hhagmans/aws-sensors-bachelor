In diesem Abschnitt wird aus die Implementierung des Projekts eingegangen. Dabei wird zunächst die Projektarchitektur erklärt und dann werden die einzelnen Komponenten des Projekts, Producer, Consumer  und die Webapplikation beschrieben. Zudem wird darauf eingegangen, wie die genutzten AWS Ressourcen gelöscht werden können und wie das Projekt in einem Docker Container verwendet werden kann. Zuletzt werden Abweichungen im Verglich zur Projektplanung besprochen.
\section{Projektarchitektur}
Um die Abhängigkeitsverwaltung und das Bauen des Projektes möglichst simpel zu gestalten, wurde für das Projekt Apache Maven \cite{maven} genutzt und das Projekt dementsprechend als Maven Projekt erstellt. \newline
Abhängigkeiten des Projekts sind der Amazon Kinesis Client in der Version 1.6.1, der Amazon Kinesis Producer in der Version 0.10.2 sowie Eclipse Jetty Servlet \cite{jetty} in der Version 9.2.14.v20151106. \newline
Teile des Codes basieren auf den Beispielen, die Amazon im AWS Kinesis Developer Guide behandelt (s. \cite{kinesis_sample_1} und \cite{kinesis_sample_2})
Die Projektarchitektur ist im Grunde genommen genau so, wie sie von Amazon in der Dokumentation von AWS Kinesis vorgestellt wird.

\begin{figure}[h!]

\includegraphics[width=1.0\textwidth]{content/images/kinesis_architecture.png}

\caption{Kinesis Architektur, wie sie von Amazon vorgegeben wird. Quelle: \cite{kinesis_concepts}}

\label{fig:aws_architecture}

\end{figure}

Wie in Abbildung \ref{fig:aws_architecture} zu sehen, setzt Amazon in der Architektur 4 Schichten voraus. Die Producer, den Kinesis Stream, die Consumer sowie weitere Services außerhalb von Kinesis. Die Daten werden von links nach rechts in der Architektur übertragen. Zunächst einmal werden die Daten in den Producern erzeugt und in den Kinesis Stream geschrieben, in denen sie in einem oder mehreren Shards einige Tage gespeichert bleiben. Ein Shard ist eine Gruppe von Datensätzen in einem Kinesis Stream, die eine feste Menge an Daten aufnehmen können. \newline
Auf der anderen Seite des Kinesis Streams befinden sich ein oder mehrere Consumer, die die Daten aus den Shards des Kinesis Streams lesen. Nach dem Lesen können die Daten zudem an andere Services weitergeleitet werden, wie beispielsweise Amazon DynamoDB, mit dem die Daten in der NoSQL-Datenbank von DynamoDB persistiert werden können. \newline
Genau diese Architektur wurde auch im Projekt umgesetzt. Es gibt eine oder mehrere Instanzen des Producers, der Temperaturdaten erzeugt. Der Producer schreibt die Daten in einen Kinesis Stream, meist nur mit einem Shard, da ein Shard für die Datenmengen dieses Projekts ausreicht. Zudem gibt es eine oder mehrere Instanzen eines Consumers, der die Daten aus dem Kinesis Stream liest und dann in eine DynamoDB Datenbank schreibt. Darüber hinaus enthält dieses Projekt zudem eine Webapplikation, die die Temperaturdaten aus DynamoDB liest und in Diagrammen ausgibt. \newline
Zudem enthält das Projekt Utility-Klassen für DynamoDB, Kinesis sowie zur Temperaturgenerierung, in denen Methoden für die entsprechenden Anforderungsgebiete ausgelagert wurden. Darüber hinaus enthält das Projekt eine "DeleteResources" Klasse, die eine Methode zur Löschung aller verwendeten Ressourcen auf Amazon Webservices bereitstellt. \newline
In der pom.xml des Projekts sind mehrere Profile eingetragen, die es ermöglichen, einzelne Klassen mit Startparametern auszuführen um somit beispielsweise den Producer mit anderen Parametern zu starten (siehe Kapitel \ref{producer}). 

\section{Producer}
\label{producer}

Der Producer ist für die Erzeugung  und Übermittlung der Temperaturwerte zuständig. Er erzeugt zunächst die Temperaturwerte und verschickt diese dann an AWS Kinesis zur weiteren Verarbeitung. Er ist also das Äquivalent zu einem Sensor, der in diesem Fall die Temperaturen aber generiert und nicht aus der Umwelt misst. Es können mehrere Instanzen des Producers erzeugt und gestartet werden um so mehrere Sensoren zu simulieren. Der Producer besteht aus einer einzelne Java-Klasse, die auf mehrere weitere Utility-Klassen zugreift. Darunter fällt die Utils-Klasse, die die Temperaturdaten erzeugt, sowie die StreamUtils-Klasse, die Methoden zum Zugriff auf AWS Kinesis Streams bereitstellt. Der Producer enthält eine Main-Methode, über die der er gestartet werden kann. Zunächst werden die übergebenen Parameter ausgelesen und gesetzt. Die Parameter sind der Kinesis Streamname, der Sensorname, wie lang der Producer ausgeführt werden soll sowie wie viele Temperaturwerte pro Sekunde erzeugt werden sollen. Zudem wird ein Objekt der StreamUtils Klasse initialisiert, damit die Methoden der Klasse benutzt werden können. Schon bei der Initialisierung der Klasse wird der erste Temperaturwert generiert, der nun als Basis für alle weiteren Temperaturwerte dieser Iteration fungiert. Es werden außerdem weitere Variablen initialisiert, zum Beispiel ein ScheduledExecutorService, mit dem die Temperaturen in bestimmten Intervallen abgesendet werden können. 
\lstinputlisting[firstline=54, lastline=56, caption=Utils.java (ll. 54-56): Initialisierung des Temperaturwertes, label=utils_init, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_init} zeigt die Methode ``getFirstTemperature'', die einen Zufallswert zwischen zwei Schranken ausgibt, der dann als erster Temperaturwert genutzt wird. Diese Schranken sind in diesem Fall -20 und 40, können aber auch im Code angepasst werden. Dementsprechend kann der initiale Temperaturwert nur innerhalb dieser Schranken liegen. Der Rückgabewert dieser Methode wird der Temperaturvariable zugewiesen.
\lstinputlisting[firstline=105, lastline=123, caption=StreamUtils.java (ll. 105-123): Erstellung eines neuen Kinesis Streams, label=create_stream, style=java]{content/listings/StreamUtils.java}
Als nächstes wird ein Kinesis-Stream erzeugt, falls nicht schon ein Stream vorhanden ist. Dazu wird mit der Methode ``describeStream'' der Kinesis Client Library ein ``DescribeStreamResult'' Objekt des Streams ermittelt (s. Quelltext \ref{create_stream}) und geprüft, ob der Stream schon erstellt wurde und aktiv ist. Wenn dies nicht der Fall ist, wird ein neuer Stream erzeugt und darauf gewartet, dass dieser aktiv wird.
\lstinputlisting[firstline=229, lastline=250, caption=TemperatureProducer.java (ll. 229-250): Initialisierung eines Callbacks um Rückmeldungen der Threads zu bekommen, label=temperatureProducer_callback, style=java]{content/listings/TemperatureProducer.java}
Wie in Quelltext \ref{temperatureProducer_callback} zu sehen, wird ein FutureCallback initialisiert, der die Möglichkeit bietet nach jeder Iteration eines Threads auf das Ergebnis dieser Iteration zu reagieren. Bei einem Fehler wird hier also eine Fehlermeldung ausgegeben, bei Erfolg wird ein neuer Temperaturwert erzeugt. 
\lstinputlisting[firstline=44, lastline=52, caption=Utils.java (ll. 44-52): Generierung des nächsten Temperaturwertes, label=utils_next, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_next} zeigt die Erzeugung eines neuen Temperaturwertes. Dazu wird mit einer jeweils etwa 33 prozentigen Wahrscheinlichkeit der Temperaturwert um 0,1 erhöht bzw. erniedrigt oder bleibt wie er vorher war. Der Rückgabewert wird zudem auf eine Dezimalstelle gerundet.

\lstinputlisting[firstline=253, lastline=264, caption=TemperatureProducer.java (ll. 253-264): Initialisierung eines Runnables zum Senden eines Records, label=temperatureProducer_runnable, style=java]{content/listings/TemperatureProducer.java}

Quelltext \ref{temperatureProducer_runnable} zeigt die Initialisierung eines Runnables, der die Temperaturdaten an Kinesis schickt. Hier werden zunächst die Temperaturdaten erzeugt, die mithilfe des Kinesis Producers aus der Amazon Kinesis Java API verschickt werden. Das Ergebnis des Sendeversuchs wird an den Callback zurückgegeben. Die Erzeugung der Daten erfolgt in der Methode ``Utils.generateData''

\lstinputlisting[firstline=73, lastline=91, caption=Utils.java (ll. 73-91): Generierung der zu verschickenden Daten, label=utils_generate_data, style=java]{content/listings/Utils.java}
Quelltext \ref{utils_generate_data} enthält die Methode ``Utils.generateData''. Hier wird mit einem Stringbuilder ein String erzeugt, der dann als Bytebuffer der aufrufenden Methode zurückgegeben wird. Der erzeugte String besteht aus der Temperatur, dem Sensornamen und der aktuellen Zeit in Millisekunden, alle getrennt durch ein Semikolon. Es wird zudem nicht einfach nur die übergebene Temperatur genommen, sondern noch einmal die nächste Temperatur generiert, obwohl dieses auch im Callback wie oben genannt passiert. Dies erhöht die Zufälligkeit der Temperaturänderungen.

\lstinputlisting[firstline=267, lastline=279, caption=TemperatureProducer.java (ll. 267-279): Status Updates jede Sekunde über ein Runnable im Executor, label=temperatureProducer_status, style=java]{content/listings/TemperatureProducer.java}
Im Producer wird nun dem ScheduledExecutorService (Variable ``EXECUTOR'') ein weiteres Runnable hinzugefügt, das einmal pro Sekunde ausgeführt wird. Dieser übergebene Task startet sofort und gibt einmal pro Sekunde den aktuellen Status der Übertragung aus (s. Quelltext \ref{temperatureProducer_status})
\lstinputlisting[firstline=285, lastline=286, caption=TemperatureProducer.java (ll. 285-286): Start der Puts zu Kinesis, label=temperatureProducer_start, style=java]{content/listings/TemperatureProducer.java}

Nach der Initialisierung aller Variablen wird nun das Verschicken der Temperaturdaten gestartet. Dies geschieht über den Aufruf in Quelltext \ref{temperatureProducer_start}. \newline
Die Methode ``executeAtTargetRate'' bekommt als Parameter den ScheduledExecutorService, der das Runnable zur Statusausgabe beinhaltet, sowie das Runnable zum Verschicken eines Records und zudem, welche Sequenznummer aktuell verschickt wird und wie lange Daten verschickt werden sollen und wie viele pro Sekunde.

\lstinputlisting[firstline=327, lastline=355, caption=TemperatureProducer.java (ll. 327-355): Die Methode exectueAtTargetRate, label=temperatureProducer_execute, style=java]{content/listings/TemperatureProducer.java}
Quelltext \ref{temperatureProducer_execute} zeigt die Methode ``executeAtTargetRate''. Hier wird dem ScheduledExecutorService ein weiteres Runnable übergeben, das das Verschicken der Daten an Kinesis koordiniert. Je nachdem welche Parameter dem Producer übergeben wurden, wird der übergebene Task nun entsprechend lange und häufig ausgeführt. Der Task selbst ist das Runnable, das vor der Methode initialisiert wurde und die Temperaturdaten an Kinesis schickt (Runnable ``putOneRecord''). \newline
Wenn alle Puts abgeschlossen sind, terminiert die Methode. Daraufhin wird noch darauf gewartet, dass alle abgeschlossenen Puts auch wirklich von Kinesis verarbeitet wurden. Dann wird der Producer terminiert. \newline
Wie man sieht, werden alle Funktionen des Producers asynchron in seperaten Threads ausgeführt. Diese werden zunächst als Runnables deklariert und im ScheduledExecutorService registriert, so dass sie in einem bestimmten Intervall ausgeführt werden. Die Methode ``executeAtTargetRate'' sorgt zudem dafür, dass nur im gewählten Intervall Daten an Kinesis verschickt werden.
\section{Consumer}
Der Consumer liest die vom Producer übermittelten Daten aus AWS Kinesis und persistiert diese in AWS DynamoDB zur weiteren Verarbeitung. Er ist eine einzelne Java-Klasse, die auf mehrere weitere Utility-Klassen zugreift. Darunter fällt die StreamUtils-Klasse, die Methoden zum Zugriff auf AWS Kinesis Streams bereitstellt sowie die Dynamo-DBUtils-Klasse, die Methoden zum Zugriff auf AWS DynamoDB bereitstellt. Der Consumer enthält eine Main-Methode, über die der er gestartet werden kann. Als Parameter wird dem Consumer der Streamname sowie der Tabellenname der DynamoDB Tabelle übergeben. Diese Parameter werden bei Start des Consumers zunächst einmal ausgelesen gesetzt. Außerdem werden jeweils eine Instanz der Streamutils Klasse sowie der DynamoDBUtils Klasse initialisiert, damit die Methoden der Klassen genutzt werden können. \newline
Zunächst wird die DynamoDB Tabelle gelöscht, die Informationen eines Checkpointers sichert, da die dort gesicherten Daten nicht mehr aktuell sind. Der Checkpointer wird nach dem Lesen einer bestimmten Menge an Temperaturen aufgerufen und speichert Informationen über die gelesen Daten in der DynamoDB Tabelle ab, zum Beispiel die Sequenznummer des letzten gelesenen Wertes. Außerdem wird die Tabelle, in der die Temperaturdaten gespeichert werden, auf Amazon DynamoDB mittels der Methode ``createTemperatureTableIfNotExists'' der DynamoDBUtils erzeugt, falls sie nicht schon existierte.
\lstinputlisting[firstline=95, lastline=99, caption=DynamoDBUtils.java (ll. 95-99): Setzung des Hashkeys und Rangekeys der Temperaturtabelle, label=DynamoDBUtils_keys, style=java]{content/listings/DynamoDBUtils.java}
Quelltext \ref{DynamoDBUtils_keys} zeigt einen Ausschnitt der Methode ``createTemperatureTableIfNotExists'', in der die Hash- und Rangekeys der Tabelle gesetzt werden. Bei der Temperaturtabelle wird als Hashkey der Sensorname gesetzt und als Rangekey der Timestamp des Sensordurchlaufs. Der Hashkey partitioniert die Daten in mehrere Blöcke, hier also in Datenblöcke der einzelnen Sensoren. Mittels des Rangekeys können die partitionierten Daten zudem sortiert werden. Zusammengenommen ergeben der Hashkey und der Rangekey den Primary Key der Daten.
\lstinputlisting[firstline=241, lastline=244, caption=TemperatureConsumer.java (ll. 241-244): Erzeugung und Starten des IRecordProcessors, label=TemperatureConsumer_recordprocessor, style=java]{content/listings/TemperatureConsumer.java}
Nach dem Erzeugen der Temperaturtabelle wird eine Instanz des Temperatureconsumers erzeugt und über eine ``IRecordProcessorFactory'' ein ``IRecordProcessor'' erzeugt und gestartet (s. Quelltext \ref{TemperatureConsumer_recordprocessor}). Der Consumer implementiert das ``IRecordProcessorFactory'' Interface und fungiert als Fabrik für den ``IRecordProcessor''. In einer inneren Klasse ist zudem das ``IRecordProcessor'' Interface implementiert. Mittels des IRecordProcessor kann über die Records innerhalb eines Kinesis Streams iteriert werden und die Daten können weiterverarbeitet werden, also bspw. in einer Datenbank persistiert werden. \newline
In der inneren Klasse wurden 3 Methoden des ``IRecordProcessor'' Interfaces implementiert. In der ``initialize'' Methode wird eine Instanz der DBUtils erzeugt. In der ``shutdown'' Methode wird der Grund des Abbruchs ins Log geschrieben und außerdem ein Eintrag in der Checkpointer Tabelle erzeugt. Die dritte implementierte Methode ist die ``processRecords'' Methode, die die Records verarbeitet.
\lstinputlisting[firstline=121, lastline=123, caption=TemperatureConsumer.java (ll. 121-123): Initialisierung von Variablen in der ``processRecords'' Methode, label=TemperatureConsumer_processrecords_init, style=java]{content/listings/TemperatureConsumer.java}
Zunächst werden wie in Quelltext \ref{TemperatureConsumer_processrecords_init} zu sehen einige Variablen initialisiert. Es wird die Variable timestamp initialisiert, die den Timestamp des aktuellen Temperaturwertes annimmt. Die Variable count entspricht der Anzahl der Temperaturwerte. Die HashMap allTemperatures nimmt die Werte aller Temperaturen auf. Der Key der Hashmap ist der Sensorname und damit der Hashkey der DynamoDB Tabelle. Die Values sind weitere HashMaps. Keys dieser Hashmaps sind die timeStamps der Temperaturen. Die Values sind die Temperaturdaten. Der Timestamp des Durchlaufs liest der ``IRecordProcessor'' als PartitionKey aus dem Stream und bildet den Rangekey.
\lstinputlisting[firstline=124, lastline=149, caption=TemperatureConsumer.java (ll. 124-149): Iteration über die Records innerhalb eines Streams, label=TemperatureConsumer_processrecords_process, style=java]{content/listings/TemperatureConsumer.java}
Der Quelltext \ref{TemperatureConsumer_processrecords_process} zeigt den Verarbeitungsprozess der Daten in der Methode ``processRecords''. Es wird über alle Records iteriert und zunächst der Timestamp als Rangekey extrahiert. Dann werden die Daten des Records extrahiert. Der im Producer erzeugte String wird dabei in die einzelnen Teile aufgeteilt und enthält die Daten für einen Temperaturwert eines Sensors, gemessen an einem bestimmten Zeitpunkt.. Als nächstes wird geprüft, ob in der Hashmap allTemperatures schon eine Hashmap für den Sensor, der den Temperaturwert erzeugt hat, vorhanden ist. Wenn ja, wird diese Hashmap aus allTemperatures gelesen, ansonsten wird eine neue erzeugt. In diese Hashmap wird dann der Temperaturwert und der Zeitpunkt eingefügt und die aktualisierte Map des Sensors wird wieder in die allTemperatures Hashmap eingefügt. Es wird ein Log mit den gelesenen Daten ausgegeben und der Zähler der Temperaturen inkrementiert.
\lstinputlisting[firstline=157, lastline=165, caption=TemperatureConsumer.java (ll. 157-165): Persistieren der Temperaturen auf DynamoDB, label=TemperatureConsumer_processrecords_persist, style=java]{content/listings/TemperatureConsumer.java}
Nach dem Lesen aller Daten dieses Durchlaufs werden die gesammelten Temperaturdaten in der DynamoDB Tabelle, wie in Quelltext \ref{TemperatureConsumer_processrecords_persist} zu sehen, persistiert. Außerdem wird der Checkpointer aufgerufen und ein Eintrag in der Checkpointer Tabelle erzeugt.
\lstinputlisting[firstline=158, lastline=184, caption=DynamoDBUtils.java (ll. 158-184): Persistierung der Daten auf DynamoDB, label=DynamoDBUtils_put, style=java]{content/listings/DynamoDBUtils.java}
Der Quelltext \ref{DynamoDBUtils_put} zeigt die Methode ``putTemperatures'' in der Klasse ``DynamoDBUtils'', die im Consumer aufgerufen wird. Hier wird jeder einzelne Sensor einzeln in einer For-Schleife abgearbeitet. Für jeden Sensor wird eine Query auf der Tabelle ausgeführt, die die Temperaturdaten eines Sensordurchlaufs für den gegebenen Sensornamen und den Timestamp zurückgibt. Das Ergebnis ist eine Liste von Maps, die entweder genau eine Map enthält oder keine, falls es noch keine Temperaturdaten für diesen Sensordurchlauf gibt. Dann wird eine neue Map erzeugt. Alle der Methode übergebenen Temperaturen werden in die Map eingefügt. Daraufhin wird die Map wieder in die DynamoDB Tabelle eingefügt und diese Tabelle persistiert. Damit sind die Temperaturen auf DynamoDB aktualisiert. \newline
Die Methode ``processRecords'' wird vom ``IRecordProcessor'' je nach Datenmenge mehrfach mit einem Teil der Daten, der aus dem Stream gelesen wurde, als Parameter aufgerufen. Wenn alle Daten gelesen wurden, bleibt der Consumer zunächst in einem Wartezustand, bis weitere Daten gelesen werden können.
\section{Webapplikation}
Die Webapplikation besteht aus einem Servlet sowie der Klasse Servletstarter, die einen Jetty Server startet und das Servlet einbindet. Auf der Website können dann die aktuellen Temperaturwerte eingesehen werden, die aus der DynamoDB-Tabelle ausgelesen werden.

\lstinputlisting[firstline=34, lastline=39, caption=ServletStarter.java (ll. 34-39): Auslesen der übergebenen Argumente in ServletStarter, label=servletStarter_init_variables, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_init_variables} werden die übergebenen Parameter ausgelesen und initialisiert. Zudem wird eine Server Instanz erzeugt, die auf dem Port 8080 betrieben wird.

\lstinputlisting[firstline=41, lastline=46, caption=ServletStarter.java (ll. 41-46): Servlet wird in Context gesetzt, label=servletStarter_context, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_context} wird der Context initialisiert und das Servlet wird in den Context eingebunden. Das Servlet ist also nach Start des Server unter der Adresse ``localhost:8080/api/GetTemperature'' erreichbar.

\lstinputlisting[firstline=48, lastline=54, caption=ServletStarter.java (ll. 48-54): Context wird den Handlern zugefügt, label=servletStarter_handler, style=java]{content/listings/ServletStarter.java}
In Quelltext \ref{servletStarter_handler} wird der Context dann den Handlern zugefügt, die Handler dem Server zugeordnet und der Server dann gestartet. \newline
Das Servlet selbst besteht aus einer doGet-Methode, die bei einem GET auf die oben genannte URL aufgerufen wird. 
\lstinputlisting[firstline=64, lastline=67, caption=TemperatureServlet.java (ll. 64-67): Aufruf der Methode zum Lesen aller Temperaturen von DynamoDB, label=temperatureServlet_getTemperatures, style=java]{content/listings/TemperatureServlet.java}
Quelltext \ref{temperatureServlet_getTemperatures} zeigt die Initialisierung einer Hashmap, die alle Temperaturdaten enthalten wird, sowie den Aufruf der Methode ``getAllSensorTemperatures'', die die HashMap befüllt.
\lstinputlisting[firstline=228, lastline=242, caption=DynamoDBUtils.java (ll. 228-242): Die Methode getAllSensorTemperatures, label=DynamoDBUtils_getAllTemps, style=java]{content/listings/DynamoDBUtils.java}
Quelltext \ref{DynamoDBUtils_getAllTemps} zeigt die Methode ``getAllSensorTemperatures'', die die oben genannte HashMap erzeugt. In der Methode werden zunächst mittels eines ``Scanrequests'' die Namen aller in der DynamoDB Tabelle vorhandenen Sensoren ermittelt. Dann wird für jeden Sensor eine eigene Hashmap erzeugt, die die Temperaturdaten enthält.
\lstinputlisting[firstline=198, lastline=217, caption=DynamoDBUtils.java (ll. 198-217): Die Methode getTemperaturesForSensor, label=DynamoDBUtils_getOneTemp, style=java]{content/listings/DynamoDBUtils.java}
Die Hashmaps der einzelnen Sensoren werden in der Methode ``getTemperaturesForSensor'' erzeugt, die in Quelltext \ref{DynamoDBUtils_getOneTemp} zu sehen ist. Hier wird zunächst eine Query mit dem Hashkey als Parameter abgesetzt, die alle Temperaturen für einen Sensor zurückliefert. Daraufhin wird über die Items der Query iteriert und die HashMap der Temperaturdaten dieses Sensors erzeugt. In der Methode ``getAllSensorTemperatures'' werden alle Hashmaps der Sensoren in einer übergeordneten Hashmap zusammengefügt. \newline
Die daraus generierte Hashmap zeigt auf eine weitere Menge von Hashmaps, die wiederum auf eine Menge von HashMaps zeigt. Die Temperaturdaten sind also schichtenweise aufgeteilt. Die erste Schicht ist die erste Hashmap, deren Keys die Sensornamen sind. Die Sensornamen zeigen jeweils auf eine weitere HashMap. Dessen Key ist der Timestamp des Laufs dieses Sensors. Wurde ein Sensor also mehrmals gestartet, hat dieser mehrere Einträge in dieser HashMap. Die Values dieser HashMap sind jeweils eine weitere HashMap. Diese enthält als Keys den Timestamp, an dem die Temperatur gemessen wurde und als Values den entsprechenden Temperaturwert. Geht man diese Hierarchie von oben nach unten durch, werden also den Sensoren eine Menge von Timestamps der Iterationen zugeordnet. Den Timestamps der Iterationen wird nun eine Menge von Temperaturen zugeordnet, die zudem jeder einen Timestamp enthalten, um sie in eine zeitliche Reihenfolge zu bringen.  \newline
In der Methode wird nun über die einzelnen Schichten dieser HashMap iteriert und dabei mittels einem PrintWriter das erzeugte HTML ausgegeben. Es wird CanvasJS \cite{canvasjs} genutzt, um die Temperaturdaten als Graphen darzustellen.

\lstinputlisting[firstline=75, lastline=89, caption=TemperatureServlet.java (ll. 75-89): Iteration über die HashMaps, label=temperatureServlet_iteration, style=java]{content/listings/TemperatureServlet.java}
Quelltext \ref{temperatureServlet_iteration} zeigt die Iteration über die HashMaps. CanvasJS nimmt ein Array an, das die Datenpunkte als y und y Werte enthält. Hier wird für jeden Sensordurchlauf ein eigenes Array erzeugt, da ja jeder Sensordurchlauf in einem eigenene Graphen dargestellt werden soll. In der innersten For-Schleife werden dem Array dann die Datenpunkte hinzugefügt. Als x Koordinate wird eine laufende Nummer vergeben, da die Timestamps der Temperaturen zu groß für die Anzeige wären und als y Koordinate wird die Temperatur gesetzt. \newline
Wenn alle Datapoint-Arrays erzeugt wurden, werden weitere Metadaten für die Generierung der Graphen ausgegeben und es wird zudem für jeden Graphen ein div Element erzeugt, in das der Graph dann generiert wird. Bei Aufrufen der Webseite wird dann eine Javascript Funktion aufgerufen, die die Graphen in den divs rendert. \newline
Die Webseite stellt nun alle Durchläufe der Sensoren dar. Für jeden Durchlauf gibt es einen Graphen, de wie oben beschrieben initialisiert wurde. CanvasJS bietet nun die Möglichkeit die Graphen zu manipulieren indem bspw. der betrachtete Zeitraum verändert wird und nur ein Teil der Daten dargestellt wird.
\section{Löschung der AWS Ressourcen}

Eine weitere Klasse ist die Klasse ``DeleteResources'', mittels der man die gestarteten Ressourcen auf Amazon Webservices wieder löschen kann, um keine weiteren Kosten zu verursachen. \newline
Die Klasse hat eine main-Methode, die zwei Argumente annimmt: Den Streamnamen sowie den Datenbank Namen der Dynamo DB Tabelle.
\lstinputlisting[firstline=24, lastline=30, caption=DeleteResources.java (ll. 24-30): Auslesen der übergebenen Argumente in DeleteResources, label=deleteresources_init_variables, style=java]{content/listings/DeleteResources.java}
In Quelltext \ref{deleteresources_init_variables} sieht man, wie die Argumente ausgelesen und gesetzt werden. Wenn nicht genau 2 Argumente übergeben werden, wird ein Standardwert für die beiden Variablen genutzt. 
\lstinputlisting[firstline=32, lastline=43, caption=DeleteResources.java (ll. 32-43): Initialisierung der Dynamo DB Utilklasse und Löschen der Tabellen, label=deleteresources_init_db, style=java]{content/listings/DeleteResources.java}
In Quelltext \ref{deleteresources_init_db} wird die DynamoDB Utilklasse initalisiert und dazu werden zunächst die benötigten Amazon Client Klassen erzeugt, die der Utilklasse bei der Initialisierung übergeben werden. Daraufhin wird die Übersichtstabelle sowie die Tabelle, die die Temperaturdaten enthält, gelöscht.
\lstinputlisting[firstline=45, lastline=49, caption=DeleteResources.java: Initialisierung der Stream Utilklasse und Löschen des Streams (ll. 45-49), label=deleteresources_init_stream, style=java]{content/listings/DeleteResources.java}
Im nächsten Abschnitt in Quelltext \ref{deleteresources_init_stream} wird dann die Stream Utilklasse initialisiert und daraufhin der Stream gelöscht. \newline
Damit sind alle Ressourcen, die auf Amazon Web Services genutzt wurden, gelöscht und es werden keine Kosten mehr zum Beispiel durch die temporäre Speicherung der Daten im Kinesis Stream verursacht.
\section{Docker}

Um die Applikation auf ein Deployment auf Amazon EC2 vorzubereiten, wurde ein Docker Image erstellt, um die Applikation letztendlich über ECS auf EC2 zu deployen. \newline
\lstinputlisting[firstline=1, lastline=2, caption=Dockerfile des Projekts, label=dockerfile, style=java]{content/listings/Dockerfile.txt}
Dieses Dockerfile ist sehr simpel gehalten und enthält nur 2 Zeilen. Wie in Quelltext \ref{dockerfile} zu sehen, basiert dieses Image auf dem Apache Maven Image \cite{maven_image}. Dieses Image enthält neben einer Java 7 Installation auch eine Maven 3.2 Installation. Zudem kopiert es bei der Generierung des Images das Projekt, wenn die Dockerfile im gleichen Ordner wie die pom.xml ist, nach ``/usr/src/app'' und führt ``mvn install'' aus. Zusätzlich dazu wird, wie in Zeile 2 beschrieben, noch ``mvn clean package'' ausgeführt, was die Applikation endgültig initialisiert. \newline
Mithilfe dieses Dockerfiles kann nun mit ``docker build -t project-image .'' ein Docker Image erzeugt werden. Über dieses Image kann dann mit dem Befehl in Quelltext \ref{start_docker} der Producer gestartet werden.
\lstinputlisting[firstline=1, lastline=1, caption=Konsolenbefehl zum Starten des Docker Images, label=start_docker, style=java]{content/listings/Start_Docker.txt}
Auch hier müssen wieder der AWS Access Key sowie der AWS Secret Key übergeben werden sowie die weiteren Parameter, die der Producer annimmt. In diesem Beispiel wird ein Stream namens ``StreamTest'' erzeugt, der Sensor Name ist ``SensorTest'' und der Producer erzeugt für 10 Sekunden 10 Records pro Sekunde. \newline
Es ist natürlich auch möglich die anderen Klassen mithilfe dieses Images zu starten, indem die Übergabeparameter geändert werden.
\section{Abweichungen im Vergleich zur Projektplanung}
In der Projektplanung wurden die Anforderungen des Projekts ermittelt und darauf basierend ein Pflichtenheft erstellt, das die Anforderungen an das Projekt präzise darstellt. Einige dieser Anforderungen konnten aber im Laufe dieses Projektes nicht erfüllt werden. Zum einen konnte die Anforderung  ``Mehrere AWS Services'' nicht erfüllt werden. Während der Entwicklung wurde klar, dass AWS Kinesis eine sehr effiziente und schnelle Lösung für die Übertragung der Daten ist und es zumindest von Amazon keine passende Alternative gibt, die für dieses Projekt genutzt werden konnte. Es wäre möglich gewesen, Amazon Kinesis Firehose  \cite{firehose} zu nutzen, das eine Variante von Kinesis darstellt, um Daten über Kinesis direkt an andere Datenbankservices wie Amazon S3 \cite{s3} weiterzuleiten, wo sie dann persistiert werden. Allerdings bietet Amazon Kinesis Firehose keine Integration für Amazon DynamoDB, das in diesem Projekt das gewählte Datenbanksystem darstellt. Eine Umstellung hätte zu viel Zeit gekostet. Genauso war für eine Eigenentwicklung, die beispielsweise auf Amazon EC2 hätte deployed werden können, am Ende des Projektes keine Zeit mehr. Daher blieb es bei der einen implementierten Variante. \newline
Die Anforderung ``Dashboard Start Stopp'' wurde auch nicht komplett umgesetzt. Die Producer lassen sich zwar stoppen und wieder starten, allerdings nicht über das Dashboard, sondern indem der EC2 Container gestoppt wird, in dem der Producer betrieben wird.  ``Dashboard Zeitskalierung'' wurde auch nicht ganz umgesetzt, es ist nur möglich beim Start eines Producers die Menge der zu erzeugenden Daten zu bestimmen und nicht, wenn ein Producer schon gestartet ist. \newline
Des weiteren wurden die Anforderungen ``Dashboard Diagramme Aktualität'' sowie ``Producer Temperatur Beeinflussung'' nicht vollständig umgesetzt. Die Diagramme sind beim Aufruf des Dashboards aktuell, werden aber nicht aktualisiert, wenn die Seite nicht aktualisiert wird. Zudem beeinflussen sich die Producer nicht gegenseitig. \newline
Dementsprechend wurden die ursprünglichen Anforderungen ``Start und Stopp des Datenstroms'', ``Mehrere AWS Services'', ``Aktualität der Daten'' sowie ``Temperaturen beeinflussen sich gegenseitig'' nicht oder nur teilweise erfüllt. \newline
In der Projektanalyse wurde zudem eine Risikoanalyse durchgeführt, die die Risiken des Projektes auflistet. Im Projekt sind die Risiken Nummer 3 und 4 zumindest teilweise auch eingetreten. Der Umfang des Projektes wurde etwas unterschätzt und dadurch wurden Teile des Projekts nicht fertig. Allerdings wurden im Rahmen der Risikoanalyse auch Gegenmaßnahmen entwickelt, um die Kosten der Risiken abzufedern. So wurde die Wichtigkeit der Anforderungen ermittelt und dementsprechend priorisiert, so dass die wichtigsten Anforderungen möglichst früh abgearbeitet wurden. Dabei wurde auch erkannt, dass einige Anforderungen für den Erfolg des Projektes nicht entscheidend sind und das Projekt nur abgerundet hätten. Daher konnte das Projekt trotz dem Eintritt zweier Risiken erfolgreich durchgeführt werden.  \newline
Das Budget von 200\texteuro{} wurde innerhalb des Projektes nicht ausgereizt, da auch entsprechend der Risikoplanung die Kosten ständig überwacht wurden. \newline
Zusammenfassend kann man also sagen, dass es einige Abweichungen im Vergleich zur Projektplanung gab, aber trotzdem alle wichtigen Anforderungen umgesetzt wurden und die Maßnahmen im Rahmen der Risikoplanung gegriffen haben.
\section{Zusammenfassung}
Insgesamt kann man sagen, dass das Projekt zufriedenstellend abgelaufen ist. Es sind zwar einige Anforderungen nicht erfüllt worden, allerdings wurden alle für das Projekt wichtigen Anforderungen erfüllt und die genutzten Amazon Webservices können evaluiert werden. Die nicht umgesetzten Anforderungen können unter Umständen in einem weiteren Projekt nach dieser Bachelorarbeit erarbeitet werden, um noch weitere Kenntnisse über Amazon Web Services zu gewinnen und das Projekt in einigen Punkten noch zu verbessern.  \newline
Positiv ist die Planungsphase und insbesondere die Risikoplanung zu sehen, dank der die wichtigsten Anforderungen erfüllt werden konnten und auch das Budget eingehalten werden konnte. \newline
Schade ist, dass die Amazon Kinesis Connectors \cite{kinesisconnector} nicht genutzt werden konnten, da die Dokumentation dieser nur recht kurz ist und zu viel Einarbeitungszeit benötigt hätte. Mittels Kinesis Connectors hätte man die Persistierung der Temperaturdaten auf DynamoDB automatisieren können, so dass gar kein Consumer mehr nötig gewesen wäre, sondern die Daten direkt von Kinesis an DynamoDB weitergeleitet werden. \newline
Zusammenfassend ist das Projekt also zufriedenstellend erfüllt worden.