In diesem Kapitel werden die genutzten Amazon Web Services Kinesis und DynamoDB betrachtet und deren Nutzen für ein Projekt dieser Art evaluiert. Zudem wird der potentielle Nutzen von AWS IoT bei Nutzung echter Sensoren evaluiert und noch einige andere Implementierungsmöglichkeiten betrachtet.
\section{Evaluation Kinesis und DynamoDB}
\label{eva_kinesis}
Amazon Kinesis war in diesem Projekt eine sehr wichtige Komponente, die es ermöglichte das Projekt schnell durchzuführen, aber auch gute Ergebnisse erzielen zu können. Kinesis ist leicht nutzbar und bietet einen guten Durchsatz der Daten. So war es ohne Probleme möglich mehrere tausend Temperaturdaten von verschiedenen Sensoren pro Sekunde über Amazon Kinesis zu übertragen und zu verarbeiten. Dabei wurde zur Vereinfachung ein einfacher kommaseparierter String erzeugt, der die Temperaturdaten enthielt, und mittels Amazon Kinesis übertragen. Dieser String wurde vom Consumer verarbeitet und die Temperaturdaten dann manuell in DynamoDB persistiert. Es ist aber auch möglich, eigene Modelklassen für die Daten zu erstellen und mittels Annotationen direkt anzugeben, welches Attribut ein Key Attribut ist usw. und die Modelklasse direkt auf DynamoDB zu persistieren. Für das vergleichsweise einfache Datenmodell dieses Projekts war dies nicht notwendig, aber für komplexere Projekte ist das ein großer Vorteil. Zudem wurde in diesem Projekt ein Kinesis Stream mit nur einem einzigen Shard genutzt. Für größere Projekte können mehr Shards genutzt werden, die den Datendurchsatz noch weiter erhöhen können.\newline
Die Nutzung von DynamoDB war in diesem Projekt ebenfalls recht einfach. Es mussten zu jedem Temperaturwert ein Hashkey sowie ein Rangekey angegeben werden, die eigentlichen Temperaturwerte konnten dann direkt in diesem Datensatz gespeichert werden. Auch eine Map kann in DynamoDB so direkt und ohne Anpassung des Formats im Gegensatz zu relationalen Datenbanken in diesem Datensatz gespeichert werden . Zudem war DynamoDB in den Testphasen recht performant und konnte mehrere tausend Datensätze pro Sekunde persistieren. Hier war es allerdings notwendig das Datenformat etwas anzupassen und pro Sensordurchlauf nur noch einen Datensatz zu erstellen und die einzelnen Temperaturwerte als Map in diesem Datensatz zu speichern und diesen Datensatz nur noch zu bearbeiten. Wurden alle Datensätze einzeln persistiert, konnte DynamoDB nur noch einige hundert Temperaturen pro Sekunde maximal persistieren. Trotz gutem Datendurchsatz ist ein passendes Datenmodell also dennoch wichtig für eine gute Performance von DynamoDB. \newline
Ein negativer Punkt in Sachen Kinesis ist die permanente Speicherung der Daten innerhalb eines Kinesis Streams. Daten, die über einen Kinesis Stream gesendet werden, werden noch bis zu einer Woche gespeichert, damit sie weiterhin von einem Consumer gelesen werden können. Das ist zunächst einmal ein positiver Punkt, allerdings ist die Speicherung vergleichsweise kostenintensiv. Wurde ein Stream nach Einsatz nicht gelöscht, wurden die übertragenen Daten im Stream persistiert, was schon nach wenigen Tagen Kosten von mehreren Dollar zur Folge hatte. Für dieses Projekt mit dieser Datenmenge kein Problem, da ja auch ein gewisses Budget gewährt worden war, bei größeren Projekten können dadurch aber unter Umständen größere Kosten entstehen, die aber vollkommen unnötig sind. Im Laufe dieses Projekts wurde keine Möglichkeit gefunden, die Persistierung der Daten in Streams schon im Vorhinein zu unterbinden, was das Monitoring der Amazon Web Services und besonders von Amazon Kinesis sehr wichtig machte, um keine unnötigen Kosten zu verursachen. \newline
Positiv zu erwähnen ist, dass die Übertragung der Daten über Kinesis in den Tests immer kostenlos war, da sich die Datenmenge noch im kostenlosen Bereich von Kinesis befand. Um innerhalb dieses Bereichs zu bleiben, wurden die Producer bewusst nur maximal einige Minuten betrieben. Bei dauerhaftem Einsatz würde die Datenmenge auch in den kostenpflichtigen Bereich steigen. Genauso waren auch die Kosten für die Nutzung von DynamoDB und Amazon EC2 im Cent- oder maximal im niedrigen Dollarbereich. \newline
Ein weiterer positiver Punkt ist die recht gute Dokumentation der verschiedenen Webservices von Amazon, die einen schnellen Einstieg ermöglicht. Die Grundlagen aller Services sind gut erklärt und auch die APIs und Client Libraries werden beschrieben. Besonders die Beispielprojekte einzelner Services sind ein guter Einstieg in AWS. Negativ ist, dass die Dokumentation über die Grundlagen meist nicht hinaus geht und im Bereich Amazon Kinesis die Kinesis Connectors nur sehr kurz beschrieben wurden, so dass diese in diesem Projekt nicht genutzt werden konnten, da es aufgrund der geringen Dokumentation zu viel Zeit gebraucht hätte die Funktionsweise dieser Library zu verstehen. \newline
Die Nutzung von Docker war im Rahmen dieses Projektes auch sehr simpel umzusetzen, da es von vornherein als Maven Projekt geplant wurde, für das es ein eigenes Docker Image gibt. Somit war nur wenig Arbeit notwendig, um das Projekt in einem Docker Container zu starten und damit war auch das Deployment auf Amazon EC2 mittels Amazon ECS kein Problem mehr. Mit Amazon ECS lassen sich in Docker Container gepackte Applikationen direkt auf Amazon EC2 deployen, was eine effiziente Möglichkeit für dieses Projekt darstellte. 
\section{Evaluation AWS IoT}
AWS IoT ist eine Service von Amazon, der zwar nicht in diesem Projekt verwendet wurde, im Rahmen dieses Themas aber so interessant ist, dass er trotzdem als weitere Alternative betrachtet werden sollte. Es bietet eine Plattform, über die IoT Geräte wie bspw. Sensoren miteinander kommunizieren können sowie AWS IoT auch mit den Geräten kommunizieren kann (s. Kapitel \ref{aws_iot}). \newline
In diesem Projekt könnte AWS IoT die Rolle von Amazon Kinesis als Kommunikationsweg der Sensoren übernehmen mit dem Unterschied, dass IoT direkt für physikalische Geräte entwickelt wurde. Wenn man also physikalische Geräte einsetzen möchte, könnte AWS IoT die effizientere Lösung sein. \newline
Vorteile sind also die Möglichkeit der direkten Anbindung physikalischer Geräte sowie die simple Kommunikationsmöglichkeit zwischen den Geräten. Zudem ist eine Anbindung an weitere Amazon Services wie bspw. DynamoDB zur Datenhaltung möglich. \newline
Negativ ist vor allem die geringe Anzahl der zu AWS IoT direkt kompatiblen Geräte sowie die bisher recht geringe Dokumentation dieser Geräte. Daher ist ein Einstieg im Moment nicht allzu einfach und mit einiger Konfigurationsarbeit verbunden. Eventuell könnte sich dieser Zustand zukünftig aber noch ändern, vor allem im Hinblick darauf, dass AWS IoT noch nicht allzu lange verfügbar ist.
\section{Evaluation anderer Implementierungsmöglichkeiten}
Bei der Ausführung dieses Projektes wurden noch einige andere Implementierungsmöglichkeiten ins Auge gefasst, die allerdings aus verschiedenen Gründen in diesem Projekt nicht umgesetzt werden konnten. \newline
Dazu zählen zum einen die bereits in Kapitel \ref{eva_kinesis} erwähnten Kinesis Connectors. Diese hätten die Projektarchitektur erheblich verändert und den Consumer überflüssig gemacht. Vorteil dieser Variante wäre gewesen, dass die Übermittlung der Daten direkt über Kinesis an DynamoDB gelaufen wäre ohne den Umweg über den Consumer, was die Aktualität der Daten näher an Echtzeit herangebracht hätte, welches eine der geplanten Anforderungen darstellt. \newline
Eine weitere Möglichkeit wäre die Nutzung anderer Datenbanksysteme gewesen. Amazon bietet neben DynamoDB zudem noch Amazon RDS an. Eine Lösung mit RDS wäre ebenfalls möglich gewesen, da das Datenmodell so simpel ist, dass auch relationale Datenbanken voraussichtlich eine ähnliche Performance hätten liefern können. Eine eigene Lösung bspw. mit Apache Cassandra wurde ebenfalls erörtert, letztendlich aufgrund von Zeitmangel aber verworfen. Es wurde auf die Lösung mit DynamoDB gesetzt, um eine weitere neue Technologie kennen zu lernen und weil diese Technologie gute Performance liefert und dank guter Dokumentation einen leichten Einstieg bot. \newline
Eine Anforderung an das Projekt war die Nutzer mehrerer AWS Services, um die unterschiedlichen AWS Services im Rahmen des Projektes evaluieren zu können, im Besonderen bei der Verwendung von großen Datenströmen. Hier hätte sich beispielsweise eine eigene Lösung mit Amazon EC2 angeboten, die allerdings für dieses Projekt zu komplex gewesen wäre. Es hätten die Funktionen von Amazon Kinesis selbst umgesetzt werden können, was bei der Zuverlässigkeit von Amazon Kinesis innerhalb des Projekts aber auch nicht notwendig ist.
\section{Zusammenfassung}
Insgesamt kann also gesagt werden, dass die genutzten Amazon Web Services für große Datenströme gut geeignet sind. Im Test konnten mehrere tausend Temperaturdaten innerhalb einer Sekunde übermittelt werden und es kann immer noch nach oben skaliert werden für einen wesentlich höheren Datendurchsatz. Für dieses Projekt war die Dokumentation der AWS Services recht gut, könnte in einigen Punkten aber noch etwas weiter gehen. \newline
In weiteren Tests könnte noch überprüft werden, ob der Durchsatz linear nach oben skalierbar ist und auch Millionen von Temperaturdaten pro Sekunde verschickt werden könnten. Dies konnte aufgrund des begrenzten Budgets im Rahmen dieser Projektarbeit nicht durchgeführt werden. 